# 7.4 Tools & Templates (One-Stop Reference)

Use this page as a copy/paste toolkit for risk, quality, and complexity scenarios. Itâ€™s designed to match how the PMP exam phrases problems (â€œwhat should you do first?â€).

---

## ðŸ“‹ Risk Register (Copy/Paste Template)
Minimum fields that make risk management actionable:

| Field | Example |
|---|---|
| **Risk ID** | R-014 |
| **Risk statement (cause â†’ event â†’ impact)** | Because the supplier has a single manufacturing site, a shutdown could delay delivery and slip the schedule by 3 weeks |
| **Category (RBS)** | External â†’ Supplier |
| **Probability** | 0.30 (or Medium) |
| **Impact** | $200k (or High) |
| **Score / priority** | PÃ—I (or High/Med/Low) |
| **Owner** | Procurement lead |
| **Strategy** | Mitigate |
| **Response actions** | Add backup supplier; negotiate penalties; weekly vendor checkpoints |
| **Trigger** | Supplier misses interim milestone |
| **Contingency plan** | Switch to backup supplier |
| **Fallback plan** | Re-sequence work; expedite shipping |
| **Status** | Active / watchlist / closed / realized |

::: tip ðŸ’¡ Exam shortcut
If a risk response requires effort, it belongs in the **schedule/backlog** with an owner. â€œWe have a planâ€ is meaningless if no work is planned.
:::

### Risk Assessment Matrix (PÃ—I)
Use this logic to prioritize (qualitative analysis):

| Probability | Impact | Score | Priority Action |
|---|---|---|---|
| **High (>70%)** | **High (>50%)** | **Critical** | Immediate mitigation + Active monitoring |
| **High** | **Low** | **High/Med** | Manage/Reduce probability |
| **Low (<30%)** | **High** | **High/Med** | Insure/Transfer or Contingency plan |
| **Low** | **Low** | **Low** | Watchlist (monitor only) |

---

## ðŸ›¡ï¸ Risk Response â€œMini-Planâ€ (Fast Template)
When you choose a strategy (avoid/mitigate/transfer/accept/escalate), make it executable:

1. **Owner**: Who is accountable?
2. **Actions**: What will we do (specific tasks)?
3. **Trigger**: What early signal tells us to start?
4. **Contingency**: If it happens, what do we execute?
5. **Fallback**: If the contingency isnâ€™t enough, what is Plan B?
6. **Residual/secondary risks**: What remains or what new risks did we create?

---

## ðŸ’° Reserves Cheat Sheet
| Reserve | Used for | In cost baseline? | Typical approval |
|---|---|---:|---|
| **Contingency reserve** | Identified risks (known-unknowns) | Yes | PM (within limits) |
| **Management reserve** | Unidentified risks (unknown-unknowns) | No | Sponsor/management via change control |

---

## âœ… Quality Metrics (Practical Examples)
Pick metrics that are observable and tied to requirements.

| Metric | What it tells you | Common use |
|---|---|---|
| **Defect density** | Defects per unit (module/story/function point) | Trend quality over time |
| **Escaped defects** | Defects found after release | Indicates weak prevention/appraisal |
| **Test pass rate** | Stability of builds and changes | CI effectiveness |
| **Cycle time / lead time** | Flow efficiency | Process improvement |
| **Rework %** | Hidden cost of poor quality | Cost of Quality driver |
| **Availability / MTTR** | Operational reliability | Service quality outcomes |

---

## ðŸ§¾ Definition of Done (Starter Checklist)
Use this as a baseline and tailor to your domain:

- Acceptance criteria met (validated with product owner/customer)
- Automated tests added/updated and passing
- Peer review complete (and feedback addressed)
- Security/compliance checks complete (as required)
- Documentation updated (user + technical as needed)
- No critical defects open for the story/release

### ðŸ“‹ Quality Audit Checklist (Are we doing the right thing?)
Use for **Manage Quality (QA)**:
1.  [ ] Are we using the correct document templates?
2.  [ ] Are code reviews happening for every PR?
3.  [ ] Is the "Definition of Done" being respected?
4.  [ ] Are safety/compliance checks being skipped?
5.  [ ] Is the defect log up to date?

---

## ðŸ› ï¸ 7 Quality Tools: Quick Pick
| If you need toâ€¦ | Useâ€¦ |
|---|---|
| Find root causes | **Fishbone** + **5 Whys** |
| Prioritize â€œvital fewâ€ causes | **Pareto chart** |
| Check process stability over time | **Control chart** |
| See data distribution/spread | **Histogram** |
| Collect frequency counts during inspection | **Checksheet** |
| Visualize steps/hand-offs | **Flowchart** |
| Explore correlation between variables | **Scatter diagram** |

---

## ðŸ“ˆ Control Chart Cheat Sheet (Simplified)
Common â€œinvestigateâ€ signals:

- Any point **outside** UCL/LCL
- A **run** of points on one side of the mean (non-random pattern)
- Clear **trend** up or down over time

Key concept pair:
- **Control limits** = process stability (statistical)
- **Specification limits** = requirement boundaries (customer/contract)

---

## ðŸ§­ Cynefin Quick Pick
| Domain | Environment feels likeâ€¦ | Best move |
|---|---|---|
| **Clear** | Known rules, repeatable work | Standardize, automate, follow best practice |
| **Complicated** | Multiple right answers | Bring experts, analyze, decide |
| **Complex** | Unpredictable, learning required | Experiment, iterate, adapt (probeâ€“senseâ€“respond) |
| **Chaotic** | Crisis, no time | Act to stabilize, then reassess |

---

## ðŸ—“ï¸ Weekly "Risk + Quality" Review Agenda (10 Minutes)
- New risks/opportunities since last review
- Top risks: triggers, actions progress, owner updates
- Recent defects: trend, root cause themes, corrective actions
- Any complexity signals (dependency surprises, stakeholder misalignment)
- Updates needed: Risk Register, Issue Log, quality checklist/DoD

---

## ðŸŽ¯ Risk Response Decision Matrix
Use this to quickly select the best response strategy:

| If the riskâ€¦ | And you haveâ€¦ | Best Strategy |
|---|---|---|
| Is **high probability** and **high impact** | Authority and budget | **Avoid** (eliminate) or **Mitigate** (reduce) |
| Is **high impact** but **low probability** | Budget for insurance/contracts | **Transfer** (insurance, warranty, fixed-price contract) |
| Is **low impact** or **low probability** | Limited budget | **Accept** (active: plan contingency; passive: do nothing) |
| Is **outside your authority** | Escalation path | **Escalate** to program/portfolio/management |
| Is an **opportunity** you want guaranteed | Resources available | **Exploit** (make it certain) |
| Is an **opportunity** but uncertain | Some resources | **Enhance** (increase probability/impact) |
| Is an **opportunity** too big for you alone | Partnership potential | **Share** (joint venture, alliance) |

---

## ðŸ“Š Quality vs. Grade Decision Table
| Scenario | Quality | Grade | Acceptable? |
|---|---|---|---|
| Economy car with no defects, meets all specs | High | Low | âœ… Yes |
| Luxury car with defects, doesn't meet specs | Low | High | âŒ No |
| Economy car with defects | Low | Low | âŒ No |
| Luxury car with no defects, exceeds specs | High | High | âœ… Yes |

**Key Takeaway**: Low grade can be acceptable (if that's what was purchased). Low quality is never acceptable.

---

## ðŸ” Root Cause Analysis Template (5 Whys)

**Problem Statement**: Deliverable was rejected by customer

1. **Why?** The feature didn't meet acceptance criteria.
2. **Why?** Acceptance criteria were misunderstood by the team.
3. **Why?** Acceptance criteria were not documented clearly.
4. **Why?** The Definition of Done doesn't require written acceptance criteria.
5. **Why?** The team never updated the DoD after the last project retrospective.

**Root Cause**: DoD is incomplete and not maintained.

**Corrective Action**: Update DoD to require documented acceptance criteria for all user stories; review and update DoD quarterly.

---

## ðŸ§­ Complexity Decision Framework

| Question | Answer | Implication |
|---|---|---|
| Are requirements clear and stable? | No | Use **iterative/adaptive** delivery |
| Can we predict outcomes with analysis? | No | Move to **experimentation** (probe-sense-respond) |
| Do we have multiple experts disagreeing? | Yes | Run **safe-to-fail experiments** to test hypotheses |
| Are there many dependencies and hand-offs? | Yes | **Map dependencies**; reduce coupling; use WIP limits |
| Is the environment changing rapidly? | Yes | **Shorten feedback cycles**; build in buffers |

---

## ðŸ“‹ Risk Audit Checklist
Use this to verify risk management effectiveness:

- [ ] Is the Risk Register reviewed at least monthly (or every sprint)?
- [ ] Are all high-priority risks assigned to owners?
- [ ] Are response actions integrated into the schedule/backlog?
- [ ] Are triggers defined and monitored for top risks?
- [ ] Have we identified new risks since the last review?
- [ ] Are issues being logged when risks occur?
- [ ] Is contingency reserve usage tracked and reported?
- [ ] Have we conducted assumption analysis recently?

---

## ðŸŽ¯ When to Use Which Quality Tool (Quick Reference)

| Situation | Tool | Why |
|---|---|---|
| "We don't know the root cause" | **Fishbone + 5 Whys** | Structured brainstorming to find causes |
| "Which defect types are most common?" | **Pareto Chart** | Prioritize the vital few (80/20 rule) |
| "Is our process stable over time?" | **Control Chart** | Detect variation patterns and special causes |
| "What's the distribution of our data?" | **Histogram** | Visualize spread and shape |
| "Need to collect defect counts in real-time" | **Checksheet** | Tally sheet for data collection |
| "How do two variables relate?" | **Scatter Diagram** | Show correlation (not causation) |
| "Where are the bottlenecks in the process?" | **Flowchart** | Map process steps and identify waste |

---

## ðŸ“ˆ Monte Carlo Interpretation Guide

How to read and use Monte Carlo simulation outputs:

### Reading the S-Curve (Cumulative Distribution)

| Position on Curve | Confidence Level | Use Case |
|---|---|---|
| **Left tail (10-20%)** | Low confidence | Best-case scenarios (rarely commit to these) |
| **P50 (middle)** | 50% confidence | Base estimate (equal chance over/under) |
| **P80** | 80% confidence | Typical commitment for external stakeholders |
| **P90** | 90% confidence | High-confidence commitments; fixed-price bids |
| **Right tail (95%+)** | Very high confidence | Safety margin; worst-case planning |

### Common Questions Answered by Monte Carlo

| Question | Monte Carlo Answer |
|---|---|
| "What's the chance we finish by June 30?" | Look up June 30 on the S-curve; read the % |
| "When can we commit with 80% confidence?" | Find P80 on the chart; read the date |
| "How much contingency do we need?" | P80 - P50 (or P90 - P50 for more buffer) |
| "Which risks drive the most variance?" | Check sensitivity analysis (tornado chart) |

---

## ðŸ“ PERT Formulas Quick Reference

| Formula | Purpose | Calculation |
|---|---|---|
| **Expected Value** | Weighted average duration | (O + 4M + P) / 6 |
| **Standard Deviation** | Single task variability | (P - O) / 6 |
| **Variance** | For adding uncertainties | ÏƒÂ² = [(P - O) / 6]Â² |
| **Project Variance** | Total critical path variance | Î£(task variances on CP) |
| **Project Ïƒ** | For z-score calculation | âˆš(Project Variance) |
| **Z-Score** | Probability calculation | (Target - Expected) / Ïƒ |

### Z-Score to Probability Table

| z-score | Probability | Meaning |
|---|---|---|
| -1.64 | 5% | Very unlikely to meet target |
| -1.28 | 10% | Unlikely |
| 0.00 | 50% | Even chance |
| 0.84 | 80% | Likely |
| 1.00 | 84% | Good chance |
| 1.28 | 90% | Very likely |
| 1.64 | 95% | Almost certain |
| 2.00 | 97.7% | Nearly guaranteed |

---

## ðŸŽ¯ Risk Response Selection Flowchart

Use this decision tree to select the best response strategy for threats:

```
Is the risk OUTSIDE your authority?
â”œâ”€â”€ YES â†’ ESCALATE to program/portfolio level
â””â”€â”€ NO â†’ Is the impact SEVERE and probability HIGH?
         â”œâ”€â”€ YES â†’ Can you ELIMINATE the cause?
         â”‚         â”œâ”€â”€ YES â†’ AVOID (change approach/scope)
         â”‚         â””â”€â”€ NO â†’ Can you REDUCE impact OR probability?
         â”‚                  â”œâ”€â”€ YES â†’ MITIGATE (reduce exposure)
         â”‚                  â””â”€â”€ NO â†’ Can you TRANSFER to third party?
         â”‚                           â”œâ”€â”€ YES â†’ TRANSFER (insurance/contract)
         â”‚                           â””â”€â”€ NO â†’ ACCEPT (active: plan contingency)
         â””â”€â”€ NO â†’ Is monitoring cost-effective?
                  â”œâ”€â”€ YES â†’ ACCEPT (active: monitor with triggers)
                  â””â”€â”€ NO â†’ ACCEPT (passive: acknowledge only)
```

### Opportunity Response Selection

```
Is the opportunity OUTSIDE your control?
â”œâ”€â”€ YES â†’ ESCALATE (let higher-ups pursue it)
â””â”€â”€ NO â†’ Can you GUARANTEE the opportunity happens?
         â”œâ”€â”€ YES â†’ EXPLOIT (eliminate uncertainty, make it certain)
         â””â”€â”€ NO â†’ Can you INCREASE the probability or impact?
                  â”œâ”€â”€ YES â†’ ENHANCE (take actions to boost it)
                  â””â”€â”€ NO â†’ Can you PARTNER with others to realize it?
                           â”œâ”€â”€ YES â†’ SHARE (joint venture)
                           â””â”€â”€ NO â†’ ACCEPT (take advantage if it occurs)
```

---

## ðŸ“Š Process Capability Quick Reference

### Interpreting Cp and Cpk

| Scenario | Cp | Cpk | Diagnosis | Action |
|---|---|---|---|---|
| Capable & centered | â‰¥1.33 | â‰ˆ Cp | Process is good | Maintain |
| Capable but off-center | â‰¥1.33 | < Cp | Process is drifting | Re-center the mean |
| Not capable | <1.33 | N/A | Too much variation | Reduce variation (improve process) |
| Barely capable | 1.0-1.33 | N/A | At risk of defects | Investigate and improve |

### Control Chart Signal Guide

| Signal | What It Means | Action |
|---|---|---|
| Point outside UCL/LCL | Special cause (assignable) | Investigate immediately |
| 7+ points on one side of mean | Non-random pattern (shift) | Investigate for systematic cause |
| 7+ points trending up/down | Trend (drift) | Investigate before it goes OOC |
| Points alternating up-down-up-down | Instability or tampering | Reduce over-adjustment |
| Points clustered near the mean | Low variation (good!) | Maintain process |
| Points clustered near control limits | High variation (bad) | Reduce variability |

---

## ðŸ’° EMV and Decision Tree Calculator

### Single Risk EMV
```
EMV = Probability Ã— Impact

Example: 30% chance of $100,000 loss
EMV = 0.30 Ã— (-$100,000) = -$30,000
```

### Multiple Risks (Sum EMVs)
| Risk | Probability | Impact | EMV |
|---|---|---|---|
| R1 | 25% | -$80,000 | -$20,000 |
| R2 | 40% | -$50,000 | -$20,000 |
| R3 | 15% | -$200,000 | -$30,000 |
| **Total** | | | **-$70,000** |

**Contingency Reserve**: At minimum $70,000 for these known risks.

### Decision Tree EMV Template
```
Decision: [Your Choice]
â”œâ”€â”€ Option A (Cost: $X)
â”‚   â”œâ”€â”€ Success (P%): Net Value = $Y Ã— P% = $_
â”‚   â””â”€â”€ Failure (1-P%): Net Value = $Z Ã— (1-P%) = $_
â”‚   EMV(A) = Sum of above = $_
â”‚
â”œâ”€â”€ Option B (Cost: $X)
â”‚   â”œâ”€â”€ Success (P%): Net Value = $Y Ã— P% = $_
â”‚   â””â”€â”€ Failure (1-P%): Net Value = $Z Ã— (1-P%) = $_
â”‚   EMV(B) = Sum of above = $_

BEST CHOICE: Option with highest EMV
```

---

## ðŸ“‹ Integrated Risk-Quality-Complexity Review Template

### Weekly Combined Review (15 minutes)

**1. Risk Status Update (5 min)**
- Any risks triggered or realized this week?
- Top 3 risks: update status, actions taken
- New risks identified?
- Issue log: any issues requiring escalation?

**2. Quality Status Update (5 min)**
- Defects found this week (internal vs escaped)
- Any quality audits or reviews conducted?
- Process improvements implemented or needed?
- DoD compliance: any stories that skipped quality steps?

**3. Complexity Check (5 min)**
- Any new dependencies or blockers discovered?
- Stakeholder alignment: any conflicts emerging?
- Technical surprises: anything harder than expected?
- Team health: signs of burnout, confusion, or resistance?

**4. Actions and Updates**
- Update Risk Register
- Update Issue Log
- Update Lessons Learned
- Adjust sprint backlog if needed

---

## ðŸ§­ Cynefin Quick Decision Guide

| If the situation feels... | You're in... | Do this... |
|---|---|---|
| Clear, obvious, everyone agrees | **Clear** | Apply best practice; standardize |
| Needs expert analysis but solvable | **Complicated** | Analyze â†’ decide â†’ execute |
| Unpredictable, learning required | **Complex** | Experiment â†’ learn â†’ adapt |
| Crisis, chaos, no time to think | **Chaotic** | Act now â†’ stabilize â†’ reassess |
| People disagree on which of the above | **Disorder** | Break it down; classify each part |

---

## ðŸ“Š Sigma Level Quick Reference

| Sigma | DPMO | Yield | Is it good? |
|---|---|---|---|
| 1Ïƒ | 691,462 | 30.85% | Terrible |
| 2Ïƒ | 308,538 | 69.15% | Poor |
| 3Ïƒ | 66,807 | 93.32% | Acceptable |
| 4Ïƒ | 6,210 | 99.38% | Good |
| 5Ïƒ | 233 | 99.977% | Excellent |
| 6Ïƒ | 3.4 | 99.99966% | World-class |

---

## âœ… Pre-Flight Checklists

### Before Risk Planning Session
- [ ] Risk Register template ready
- [ ] Historical risks from similar projects reviewed
- [ ] RBS (Risk Breakdown Structure) selected
- [ ] Stakeholders invited (diverse perspectives)
- [ ] Risk thresholds defined (from Risk Management Plan)

### Before Quality Gate
- [ ] All acceptance criteria documented
- [ ] Checklists prepared
- [ ] Inspectors/reviewers identified
- [ ] Defect logging process ready
- [ ] Root cause analysis tools available (if needed)

### Before Complexity Decision
- [ ] Project complexity scored
- [ ] Delivery approach aligned with complexity level
- [ ] Feedback loops designed
- [ ] Experiment safe-to-fail boundaries defined
- [ ] Escalation path clear



