# Prometheus Configuration with Alert Rules

---
# Prometheus Configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      external_labels:
        cluster: 'pmp-study-prod'
        environment: 'production'

    # AlertManager configuration
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093

    # Load alert rules
    rule_files:
      - '/etc/prometheus/alerts/*.yml'

    # Scrape configurations
    scrape_configs:
      # Prometheus itself
      - job_name: 'prometheus'
        static_configs:
        - targets: ['localhost:9090']

      # Kubernetes API Server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https

      # Kubernetes Nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
        - role: node
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)

      # Application Services
      - job_name: 'application-services'
        kubernetes_sd_configs:
        - role: pod
          namespaces:
            names:
            - production
        relabel_configs:
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
          action: keep
          regex: true
        - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
          action: replace
          target_label: __metrics_path__
          regex: (.+)
        - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
          action: replace
          regex: ([^:]+)(?::\d+)?;(\d+)
          replacement: $1:$2
          target_label: __address__
        - action: labelmap
          regex: __meta_kubernetes_pod_label_(.+)
        - source_labels: [__meta_kubernetes_namespace]
          action: replace
          target_label: namespace
        - source_labels: [__meta_kubernetes_pod_name]
          action: replace
          target_label: pod

      # PostgreSQL Database
      - job_name: 'postgres'
        static_configs:
        - targets:
          - 'postgres-exporter:9187'
        relabel_configs:
        - source_labels: [__address__]
          target_label: instance
          replacement: 'postgres-production'

      # Redis Cache
      - job_name: 'redis'
        static_configs:
        - targets:
          - 'redis-exporter:9121'
        relabel_configs:
        - source_labels: [__address__]
          target_label: instance
          replacement: 'redis-production'

      # Node Exporter (Infrastructure)
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - source_labels: [__address__]
          regex: '(.*):10250'
          replacement: '${1}:9100'
          target_label: __address__

---
# Prometheus Alert Rules
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-alerts
  namespace: monitoring
data:
  # Critical Alerts (P1)
  critical-alerts.yml: |
    groups:
      - name: critical_alerts
        interval: 30s
        rules:
          - alert: ServiceDown
            expr: |
              sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
              /
              sum(rate(http_requests_total[5m])) by (service)
              > 0.05
            for: 5m
            labels:
              severity: critical
              priority: P1
            annotations:
              summary: 'Service {{ $labels.service }} is down'
              description: 'Error rate {{ $value | humanizePercentage }} for 5 minutes'
              runbook_url: 'https://runbooks.pmpstudy.com/service-down'

          - alert: DatabaseDown
            expr: up{job="postgres"} == 0
            for: 1m
            labels:
              severity: critical
              priority: P1
            annotations:
              summary: 'PostgreSQL database is down'
              runbook_url: 'https://runbooks.pmpstudy.com/database-down'

  # High Priority Alerts (P2)
  high-alerts.yml: |
    groups:
      - name: high_priority_alerts
        interval: 1m
        rules:
          - alert: HighErrorRate
            expr: |
              sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
              /
              sum(rate(http_requests_total[5m])) by (service)
              > 0.01
            for: 10m
            labels:
              severity: high
              priority: P2
            annotations:
              summary: 'High error rate in {{ $labels.service }}'
              runbook_url: 'https://runbooks.pmpstudy.com/high-error-rate'

          - alert: HighLatency
            expr: |
              histogram_quantile(0.95,
                sum(rate(http_request_duration_seconds_bucket[5m])) by (le, service)
              ) > 0.5
            for: 10m
            labels:
              severity: high
              priority: P2
            annotations:
              summary: 'High latency in {{ $labels.service }}'
              runbook_url: 'https://runbooks.pmpstudy.com/high-latency'

  # Warning Alerts (P3)
  warning-alerts.yml: |
    groups:
      - name: warning_alerts
        interval: 2m
        rules:
          - alert: ElevatedErrorRate
            expr: |
              sum(rate(http_requests_total{status=~"5.."}[5m])) by (service)
              /
              sum(rate(http_requests_total[5m])) by (service)
              > 0.005
            for: 15m
            labels:
              severity: warning
              priority: P3
            annotations:
              summary: 'Elevated error rate in {{ $labels.service }}'
              runbook_url: 'https://runbooks.pmpstudy.com/elevated-error-rate'

          - alert: BackupJobFailure
            expr: time() - max(backups_last_success_timestamp_seconds) > 86400
            for: 0m
            labels:
              severity: warning
              priority: P3
            annotations:
              summary: 'Backup job has not succeeded in 24 hours'
              runbook_url: 'https://runbooks.pmpstudy.com/backup-failure'
